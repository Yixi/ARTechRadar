<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>Name</key>
		<string>Lightweight Architecture Decision Records</string>
		<key>Number</key>
		<integer>1</integer>
		<key>Description</key>
		<string>Much documentation can be replaced with highly readable code and tests. In a world of evolutionary architecture, however, it&apos;s important to record certain design decisions for the benefit of future team members as well as for external oversight. Lightweight Architecture Decision Records is a technique for capturing important architectural decisions along with their context and consequences. We recommend storing these details in source control, instead of a wiki or website, as then they can provide a record that remains in sync with the code itself. For most projects, we see no reason why you wouldn&apos;t want to use this technique.</string>
		<key>Level</key>
		<string>ADOPT</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.08</real>
			<key>Z</key>
			<real>-0.08</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Applying product management to internal platforms</string>
		<key>Number</key>
		<integer>2</integer>
		<key>Description</key>
		<string>We&apos;ve seen a steep increase in interest in the topic of digital platforms over the past 12 months. Companies looking to roll out new digital solutions quickly and efficiently are building internal platforms, which offer teams self-service access to the business APIs, tools, knowledge and support necessary to build and operate their own solutions. We find that these platforms are most effective when they&apos;re given the same respect as an external product offering. Applying product management to internal platforms means establishing empathy with internal consumers (read: developers) and collaborating with them on the design. Platform product managers establish roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Some owners even create a brand identity for the internal platform and use that to market the benefits to their colleagues. Platform product managers look after the quality of the platform, gather usage metrics, and continuously improve it over time. Treating the platform as a product helps to create a thriving ecosystem and avoids the pitfall of building yet another stagnant, underutilized service-oriented architecture.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.1</real>
			<key>Z</key>
			<real>-0.02</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Architectural fitness function</string>
		<key>Number</key>
		<integer>3</integer>
		<key>Description</key>
		<string>Borrowed from evolutionary computing, a fitness function is used to summarize how close a given design solution is to achieving the set aims. When defining an evolutionary algorithm, the designer seeks a ‘better’ algorithm; the fitness function defines what ‘better’ means in this context. An architectural fitness function, as defined in Building Evolutionary Architectures, provides an objective integrity assessment of some architectural characteristics, which may encompass existing verification criteria, such as unit testing, metrics, monitors, and so on. We believe architects can communicate, validate and preserve architectural characteristics in an automated, continual manner, which is the key to building evolutionary architectures.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.12</real>
			<key>Z</key>
			<real>-0.02</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Autonomous bubble pattern</string>
		<key>Number</key>
		<integer>4</integer>
		<key>Description</key>
		<string>Many organizations we work with are trying hard to use modern engineering approaches to build new capabilities and features, while also having to coexist with a long tail of legacy systems. An old strategy that, based on our experience, has turned out to be increasingly helpful in these scenarios is Eric Evans&apos;s Autonomous bubble pattern. This approach involves creating a fresh context for new application development that is shielded from the entanglements of the legacy world. This is a step beyond just using an anticorruption layer. It gives the new bubble context full control over its backing data, which is then asynchronously kept up-to-date with the legacy systems. It requires some work to protect the boundaries of the bubble and keep both worlds consistent, but the resulting autonomy and reduction in development friction is a first bold step toward a modernized future architecture.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.15</real>
			<key>Z</key>
			<real>-0.02</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Chaos Engineering</string>
		<key>Number</key>
		<integer>5</integer>
		<key>Description</key>
		<string>In previous editions of the Radar, we&apos;ve talked about using Chaos Monkey from Netflix to test how a running system is able to cope with outages in production by randomly disabling instances and measuring the results. Chaos Engineering is the nascent term for the wider application of this technique. By running experiments on distributed systems in production, we&apos;re able to build confidence that those systems work as expected under turbulent conditions. A good place to start understanding this technique is the Principles of Chaos Engineering website.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.17</real>
			<key>Z</key>
			<real>-0.05</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Domain-scoped events</string>
		<key>Number</key>
		<integer>6</integer>
		<key>Description</key>
		<string>It’s important to remember that encapsulation applies to events and event-driven architectures just as it applies to other areas of software. In particular, think about the scope of an event and whether we expect it to be consumed within the same application, the same domain or across an entire organization. A domain-scoped event will be consumed within the same domain as it’s published, as such we expect the consumer to have access to a certain context, resources or references in order to act on the event. If the consumption is happening more widely within an organization, the contents of the event might well need to be different, and we need to take care not to &quot;leak&quot; implementation details that other domains then come to depend upon.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.19</real>
			<key>Z</key>
			<real>-0.08</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Micro frontends</string>
		<key>Number</key>
		<integer>8</integer>
		<key>Description</key>
		<string>We&apos;ve seen significant benefits from introducing microservices architectures, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we&apos;ve also seen many teams create front-end monoliths — a single, large and sprawling browser application — on top of their back-end services. Our preferred (and proven) approach is to split the browser-based code into micro frontends. In this approach, the web application is broken down into its features, and each feature is owned, frontend to backend, by a different team. This ensures that every feature is developed, tested and deployed independently from other features. Multiple techniques exist to recombine the features — sometimes as pages, sometimes as components — into a cohesive user experience.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Pipelines for infrastructure as code</string>
		<key>Number</key>
		<integer>9</integer>
		<key>Description</key>
		<string>The use of continuous delivery pipelines to orchestrate the release process for software has become a mainstream concept. However, automatically testing changes to infrastructure code isn’t as widely understood. Continuous integration (CI) and continuous delivery (CD) tools can be used to test server configuration (e.g., Chef cookbooks, Puppet modules, Ansible playbooks), server image building (e.g., Packer), environment provisioning (e.g., Terraform, CloudFormation) and integration of environments. The use of pipelines for infrastructure as code enables errors to be found before changes are applied to operational environments — including environments used for development and testing. They also offer a way to ensure that infrastructure tooling is run consistently, from CI/CD agents, as opposed to being run from individual workstations. Some challenges remain, however, such as the longer feedback loops associated with standing up containers and virtual machines. Still, we&apos;ve found this to be a valuable technique.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Polycloud</string>
		<key>Number</key>
		<integer>10</integer>
		<key>Description</key>
		<string>Organizations are becoming more comfortable with the Polycloud strategy — rather than going &quot;all-in&quot; with one provider, they are passing different types of workloads to different providers based on their own strategy. Some of them apply the best-of-breed approach, for example: putting standard services on AWS, but using Google for machine learning and data-oriented applications and Azure for Microsoft Windows applications. For some organizations this is a cultural and business decision. Retail businesses, for example, often refuse to store their data on Amazon and they distribute load to different providers based on their data. This is different to a cloud-agnostic strategy of aiming for portability across providers, which is costly and forces lowest-common-denominator thinking. Polycloud instead focuses on using the best match that each cloud provider offers.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Hosted identity management as a service</string>
		<key>Number</key>
		<integer>7</integer>
		<key>Description</key>
		<string>Identity management is a critical platform component. External users on mobile apps need to be authenticated, developers need to be given access to delivery infrastructure components, and microservices may need to identify themselves to other microservices. You should ask yourself whether identity management should be “self-hosted”. In our experience, a hosted identity management as a service (SaaS) solution is preferable. We believe that top-tier hosted providers such as Auth0 and Okta can provide better uptime and security SLAs. That said, sometimes self-hosting the solution is a realistic decision, especially for enterprises that have the operational discipline and resources to do so safely. Large enterprise identity solutions typically offer a much more expansive range of capabilities such as centralized entitlements, governance reporting and separation of duties management among others. However, these concerns are typically more relevant for employee identities, especially in regulated enterprises with legacy systems.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.23</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Polycloud</string>
		<key>Number</key>
		<integer>17</integer>
		<key>Description</key>
		<string>The major cloud providers (Amazon, Microsoft and Google) are locked in an aggressive race to maintain parity on core capabilities while their products are differentiated only marginally. This is causing a few organizations to adopt a Polycloud strategy — rather than going ‘all-in’ with one provider, they are passing different types of workloads to different providers in a best-of-breed approach. This may involve, for example, putting standard services on AWS, but using Google for machine learning, Azure for .NET applications that use SQLServer, or potentially using the Ethereum Consortium Blockchain solution. This is different than a cloud-agnostic strategy of aiming for portability across providers, which is costly and forces lowest-common-denominator thinking. Polycloud instead focuses on using the best that each cloud offers.

</string>
		<key>Level</key>
		<string>ASSESS</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.28</real>
			<key>Z</key>
			<real>-0.28</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>CI theatre</string>
		<key>Number</key>
		<integer>22</integer>
		<key>Description</key>
		<string>We&apos;ve long been advocates of continuous integration (CI), and we were pioneers in building CI server programs to automatically build projects on check-ins. Used well, these programs run as a daemon process on a shared project mainline that developers commit to daily. The CI server builds the project and runs comprehensive tests to ensure the whole software system is integrated and is in an always-releasable state, thus satisfying the principles of continuous delivery. Sadly, many developers simply set up a CI server and falsely assume they are &quot;doing CI&quot; when in reality they miss out on all the benefits. Common failure modes include: running CI against a shared mainline but with infrequent commits, so integration isn&apos;t really continuous; running a build with poor test coverage; allowing the build to stay red for long periods; or running CI against feature branches which results in continuous isolation. The ensuing &quot;CI theatre&quot; might make people feel good, but would fail any credible CI certification test.</string>
		<key>Level</key>
		<string>HOLD</string>
		<key>Quadrant</key>
		<string>Techniques</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.35</real>
			<key>Z</key>
			<real>-0.35</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Google Cloud Platform</string>
		<key>Number</key>
		<integer>26</integer>
		<key>Description</key>
		<string>As Google Cloud Platform (GCP) has expanded in terms of available geographic regions and maturity of services, customers globally can now seriously consider it for their cloud strategy. In some areas, GCP has reached feature parity with its main competitor, Amazon Web Services, while in other areas it has differentiated itself — notably with accessible machine learning platforms, data engineering tools, and a workable Kubernetes as a service solution (GKE). In practice, our teams have nothing but praise for the developer experience working with the GCP tools and APIs.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Platforms</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.2</real>
			<key>Z</key>
			<real>0.1</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Google Cloud Platform</string>
		<key>Number</key>
		<integer>30</integer>
		<key>Description</key>
		<string>As Google Cloud Platform (GCP) has expanded in terms of available geographic regions and maturity of services, customers globally can now seriously consider it for their cloud strategy. In some areas, GCP has reached feature parity with its main competitor, Amazon Web Services, while in other areas it has differentiated itself — notably with accessible machine learning platforms, data engineering tools, and a workable Kubernetes as a service solution (GKE). In practice, our teams have nothing but praise for the developer experience working with the GCP tools and APIs.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Platforms</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.2</real>
			<key>Z</key>
			<real>0.1</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>GKE</string>
		<key>Number</key>
		<integer>40</integer>
		<key>Description</key>
		<string>While the software development ecosystem is converging on Kubernetes as the orchestration platform for containers, running Kubernetes clusters remains operationally complex. GKE (Google Kubernetes Engine) is a managed Kubernetes solution for deploying containerized applications that alleviates the operational overhead of running and maintaining Kubernetes clusters. Our teams have had a good experience using GKE, with the platform doing the heavy lifting of applying security patches, monitoring and auto-repairing the nodes, and managing multicluster and multiregion networking. In our experience, Google&apos;s API-first approach in exposing platform capabilities, as well as using industry standards such as OAuth for service authorization, improve the developer experience. It&apos;s important to consider that GKE is under rapid development which, despite the developers&apos; best efforts to abstract consumers from underlying changes, has impacted us temporarily in the past. We&apos;re expecting continuous improvement around maturity of Infrastructure as code with Terraform on GKE and similar tools.</string>
		<key>Level</key>
		<string>ADOPT</string>
		<key>Quadrant</key>
		<string>Platforms</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>-0.25</real>
			<key>Z</key>
			<real>0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>jsoniter</string>
		<key>Number</key>
		<integer>58</integer>
		<key>Description</key>
		<string>If you&apos;re looking for a JSON encoder/decoder with high performance in Go and Java, check out the open source jsoniter library. The library is compatible with the standard JSON encoding package in Go.</string>
		<key>Level</key>
		<string>TRIAL</string>
		<key>Quadrant</key>
		<string>Tools</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>0.2</real>
			<key>Z</key>
			<real>-0.2</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Flow</string>
		<key>Number</key>
		<integer>65</integer>
		<key>Description</key>
		<string>Flow is a static type checker for JavaScript that allows you to add type checking across the codebase incrementally. Unlike Typescript, which is a different language, Flow can be added incrementally to an existing JavaScript codebase supporting the 5th, 6th and 7th editions of ECMAScript. We suggest adding Flow to your continuous integration pipeline, starting with the code that concerns you most. Flow adds to the clarity of the code, increases the reliability of refactoring and catches type-related bugs early during the build.</string>
		<key>Level</key>
		<string>HOLD</string>
		<key>Quadrant</key>
		<string>Tools</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>0.3</real>
			<key>Z</key>
			<real>-0.3</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>Yarn</string>
		<key>Number</key>
		<integer>76</integer>
		<key>Description</key>
		<string>Yarn is a new package manager that replaces the existing workflow for the npm client while remaining compatible with the npm registry. With the npm client, we may end up with a different tree structure under node_modules based on the order that dependencies are installed. This nondeterministic nature can cause &quot;works on my machine&quot; problems. By breaking the installation steps into resolution, fetching and linking, Yarn avoids these issues using deterministic algorithms and lockfiles and thus guarantees repeatable installations. We&apos;ve also seen significantly faster builds in our continuous integration (CI) environment because of Yarn caching all the packages it downloads.</string>
		<key>Level</key>
		<string>HOLD</string>
		<key>Quadrant</key>
		<string>Tools</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>0.3</real>
			<key>Z</key>
			<real>-0.1</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>ARKit&amp;ARCore</string>
		<key>Number</key>
		<integer>87</integer>
		<key>Description</key>
		<string>We&apos;ve seen a flurry of activity in mobile augmented reality much of it fueled by ARKit and ARCore, the native AR libraries used by Apple and Google, respectively. These libraries are bringing mobile AR technologies to the mainstream. However, the challenge will be for companies to find use cases that go beyond gimmicky and provide genuine solutions that actually enhance the user experience.</string>
		<key>Level</key>
		<string>ASSESS</string>
		<key>Quadrant</key>
		<string>Language&amp;Frameworks</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>0.3</real>
			<key>Z</key>
			<real>0.1</real>
		</dict>
	</dict>
	<dict>
		<key>Name</key>
		<string>CSS-In-JS</string>
		<key>Number</key>
		<integer>91</integer>
		<key>Description</key>
		<string>CSS in JS is a technique of writing CSS styling in the JavaScript programming language. This encourages a common pattern of writing the styling with the JavaScript component it applies to, co-locating presentational and logical concerns. The new players — including JSS, emotion and styled-components — rely on the tooling to translate the CSS-in-JS code to separate CSS stylesheets, to make them suitable for browser consumption. This is the second-generation approach to writing CSS in JavaScript and unlike the previous approaches doesn’t rely on in-line styles. That means it provides the benefit of supporting all CSS features, sharing of CSS using the npm ecosystem and utilization of components across multiple platforms. Our teams have found styled-components working well with component-based frameworks, such as React, and unit testing of CSS with jest-styled-components. This space is new and rapidly changing; the approach requires some effort for manual debugging of the generated class names in the browser, and it may not apply to some projects where the front-end architecture does not support reusing components and requires global styling.</string>
		<key>Level</key>
		<string>ASSESS</string>
		<key>Quadrant</key>
		<string>Language&amp;Frameworks</string>
		<key>Position</key>
		<dict>
			<key>X</key>
			<real>0.1</real>
			<key>Z</key>
			<real>0.3</real>
		</dict>
	</dict>
</array>
</plist>
